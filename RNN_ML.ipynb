{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TUDQuqflyIR1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YY53F33zI5I",
    "outputId": "93eb4e0d-fcb0-4dd3-a399-95feac35fe13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bOTPnLBYzYbD"
   },
   "outputs": [],
   "source": [
    "data_path = '/content/drive/My Drive/Machine_Learning_Data/classification.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thlSXWXL0YE6",
    "outputId": "bb9aab66-c8ac-4baa-bc1a-a8e5f3cd77cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  emotion\n",
      "0                              feel incredibly weepy        0\n",
      "1                      feeling contented wife mother        1\n",
      "2  pick novels feel like dropping luggage signing...        1\n",
      "3  little extra interest right feeling like husba...        1\n",
      "4  feel become even lot vital high eighty five we...        1\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xGh2GLnp0_Zq"
   },
   "outputs": [],
   "source": [
    "# Séparation des données en entrée (textes) et étiquettes (sentiments)\n",
    "texts = df['text'].values  # tous les textes sont stockés dans le tableau texts\n",
    "labels = df['emotion'].values  # toutes les étiquettes sont stockées dans le tableau labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sBgzIxsS-ix3"
   },
   "outputs": [],
   "source": [
    "# Tokenisation des textes\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# Padding des séquences\n",
    "padded_sequences = pad_sequences(sequences, maxlen=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEkxoNFozzF9",
    "outputId": "ee60590d-57c1-4168-b483-bb2f94398be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement: 22626\n",
      "Taille de l'ensemble de validation: 2828\n",
      "Taille de l'ensemble de test: 2829\n"
     ]
    }
   ],
   "source": [
    "# Division des données en ensembles d'entraînement, de validation et de test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Afficher la taille de chaque ensemble\n",
    "print(f\"Taille de l'ensemble d'entraînement: {len(X_train)}\")\n",
    "print(f\"Taille de l'ensemble de validation: {len(X_val)}\")\n",
    "print(f\"Taille de l'ensemble de test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oX2QNo5Dz3xb"
   },
   "outputs": [],
   "source": [
    "#  Construction du modèle avec régularisation\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128, input_length=150))  # Augmentation de la dimension de l'embedding\n",
    "model.add(GRU(units=32, return_sequences=True, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))  # Réduction des unités avec régularisation L2\n",
    "model.add(GRU(units=16, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.4))  # Augmentation du taux de dropout\n",
    "model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcUsYBfBz60g",
    "outputId": "d2ebd57d-2416-4cd9-8485-082bfe07159f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "354/354 [==============================] - 24s 52ms/step - loss: 0.6993 - accuracy: 0.8148 - val_loss: 0.2859 - val_accuracy: 0.9346\n",
      "Epoch 2/10\n",
      "354/354 [==============================] - 8s 21ms/step - loss: 0.2022 - accuracy: 0.9638 - val_loss: 0.2381 - val_accuracy: 0.9406\n",
      "Epoch 3/10\n",
      "354/354 [==============================] - 7s 19ms/step - loss: 0.1468 - accuracy: 0.9799 - val_loss: 0.2017 - val_accuracy: 0.9516\n",
      "Epoch 4/10\n",
      "354/354 [==============================] - 7s 18ms/step - loss: 0.1245 - accuracy: 0.9855 - val_loss: 0.2048 - val_accuracy: 0.9484\n",
      "Epoch 5/10\n",
      "354/354 [==============================] - 6s 18ms/step - loss: 0.1129 - accuracy: 0.9889 - val_loss: 0.2189 - val_accuracy: 0.9448\n",
      "Epoch 6/10\n",
      "354/354 [==============================] - 5s 15ms/step - loss: 0.1037 - accuracy: 0.9912 - val_loss: 0.2085 - val_accuracy: 0.9473\n",
      "Epoch 7/10\n",
      "354/354 [==============================] - 7s 21ms/step - loss: 0.1000 - accuracy: 0.9906 - val_loss: 0.2198 - val_accuracy: 0.9448\n",
      "Epoch 8/10\n",
      "354/354 [==============================] - 5s 15ms/step - loss: 0.0961 - accuracy: 0.9920 - val_loss: 0.2200 - val_accuracy: 0.9455\n",
      "Epoch 9/10\n",
      "354/354 [==============================] - 7s 19ms/step - loss: 0.0911 - accuracy: 0.9936 - val_loss: 0.2185 - val_accuracy: 0.9441\n",
      "Epoch 10/10\n",
      "354/354 [==============================] - 5s 15ms/step - loss: 0.0857 - accuracy: 0.9940 - val_loss: 0.2262 - val_accuracy: 0.9455\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTjeu6wJz72t",
    "outputId": "48f0f181-8224-4569-af87-413e01406612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 1s 7ms/step - loss: 0.2167 - accuracy: 0.9509\n",
      "Loss: 0.2167314887046814, Accuracy: 0.9508660435676575\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4RhrSdTAZSw",
    "outputId": "6a81b437-8da6-427d-8082-02ffd63553db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Après l'entraînement\n",
    "model.save('/content/drive/My Drive/Machine_Learning_Data/sentiment_analysis_model.h5')\n",
    "\n",
    "\n",
    "# Sauvegarde du tokenizer\n",
    "with open('/content/drive/My Drive/Machine_Learning_Data/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
